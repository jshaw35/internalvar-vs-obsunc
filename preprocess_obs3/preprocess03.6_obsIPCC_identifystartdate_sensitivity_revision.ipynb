{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5702ab-4316-47a2-af40-56d7ce8ccb57",
   "metadata": {},
   "source": [
    "# Identify when a record begins based on data availability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede891f-af88-4e6d-90de-32be78682d2b",
   "metadata": {},
   "source": [
    "## Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d37ff0a-6540-4fc2-9654-dc2faac44e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7faed9-fd82-480f-8918-48b2655ec5c1",
   "metadata": {},
   "source": [
    "### Collect file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb091ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "obslens_tseries_dir = '/glade/u/home/jonahshaw/w/trend_uncertainty/nathan/OBS_LENS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13704afb-7364-487f-8f97-b08d1a564d37",
   "metadata": {},
   "source": [
    "#### Collect GISTEMP 5x5 file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3babb705-2f59-40e2-8701-c1cc3827b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gistemp_5x5_95_files = glob.glob('%s/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.95/ensembleChunk_5x5_????.nc' % obslens_tseries_dir)\n",
    "gistemp_5x5_95_files.sort()\n",
    "\n",
    "gistemp_5x5_70_files = glob.glob('%s/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.70/ensembleChunk_5x5_????.nc' % obslens_tseries_dir)\n",
    "gistemp_5x5_70_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574e91b-ac98-4553-a6a7-7173e935e1bb",
   "metadata": {},
   "source": [
    "#### Collect HadCRUT5 file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9d6c4-4e77-4db8-b5a0-54589c5c984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadcrut5_95_files = glob.glob('%s/HadCRUT5/20240820/xagg/HadCRUT.5.0.2.0.analysis.anomalies.*.nc' % obslens_tseries_dir)\n",
    "hadcrut5_95_files = [i for i in hadcrut5_95_files if \"Trends\" not in i]\n",
    "hadcrut5_95_files.sort()\n",
    "\n",
    "hadcrut5_70_files = glob.glob('%s/HadCRUT5/20240820/xagg/HadCRUT.5.0.2.0.analysis.anomalies.*.nc' % obslens_tseries_dir)\n",
    "hadcrut5_70_files = [i for i in hadcrut5_70_files if \"Trends\" not in i]\n",
    "hadcrut5_70_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd0636",
   "metadata": {},
   "source": [
    "#### Collect BEST file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac5c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_95_files = ['%s/BEST/20250320/xagg/threshold_0.95/Land_and_Ocean_LatLong1.nc' % obslens_tseries_dir]\n",
    "\n",
    "best_70_files = ['%s/BEST/20250320/xagg/threshold_0.70/Land_and_Ocean_LatLong1.nc' % obslens_tseries_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef157e9",
   "metadata": {},
   "source": [
    "## Identify a start year based on data availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a9d71",
   "metadata": {},
   "source": [
    "Less conservative annual averaging.  \n",
    "To quote Lenssen et al. (2019) \"To have coverage for a year it must have coverage for at least three seasons, which requires at least 2 months in the season.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7514bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_data(\n",
    "    ds: xr.DataArray,\n",
    "    season_threshold: int=3,\n",
    "    intraseason_threshold: int=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Mask data if any season is missing more than one month.\n",
    "    To quote Lenssen et al. (2019) \"To have coverage for a year it must have coverage for at least \n",
    "    three seasons, which requires at least 2 months in the season.”\n",
    "\n",
    "    Args:\n",
    "        ds (xr.DataArray): Input data\n",
    "\n",
    "    Returns:\n",
    "        ds (xr.DataArray): Mask of availability!\n",
    "    \"\"\"\n",
    "    availability = ds[\"time.season\"].where(~np.isnan(ds))\n",
    "    \n",
    "    complete_seasons = 0\n",
    "    seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "    for _szn in seasons:\n",
    "        complete_seasons += ((availability == _szn).sum(dim=\"time\") >= intraseason_threshold)\n",
    "        \n",
    "    return complete_seasons >= season_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c4f3d",
   "metadata": {},
   "source": [
    "The simplest approach excludes too much data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84d6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startyear1(\n",
    "    data_annual: xr.DataArray,\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        data_annual (xr.DataArray): Actual data in an annual mean resolution. Remember use skipna=False!\n",
    "\n",
    "    Returns:\n",
    "        startyear_full: xarray DataArray with the start year for each region.\n",
    "    \"\"\"\n",
    "    # Compute the last nan year and step one year forward.\n",
    "    startyear = data_annual[\"year\"].where(np.isnan(data_annual)).max(dim=\"year\") + 1\n",
    "\n",
    "    complete_tseries = ~np.isnan(data_annual).any(dim=\"year\") # Identify regions without any nans\n",
    "    absent_tseries = (startyear == data_annual.year[-1]) | (startyear == data_annual.year[-1] + 1) # Identify regions with all nans\n",
    "\n",
    "    # Set the complete years to the record start year\n",
    "    startyear_full = xr.where(complete_tseries, data_annual.year[0], startyear)\n",
    "    # Set the years with consistent missing data to no start year\n",
    "    startyear_full = xr.where(absent_tseries, np.nan, startyear_full)\n",
    "    \n",
    "    return startyear_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17bf2a",
   "metadata": {},
   "source": [
    "This approach looks for availability for windows of various lengths beginning in the start year. It seems to work best because data gaps become less important as the record becomes longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71962e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startyear_running_availability(\n",
    "    mask_annual: xr.DataArray,\n",
    "    windows: list = [5, 10, 20, 40, 80],\n",
    "    fraction: float = 0.6666,\n",
    "    fillvalue: int = 2100,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function identifies start years from a Boolean mask indicating \n",
    "    annual data availability input using two conditions:\n",
    "        1. The data is present during the startyear.\n",
    "        2. There is at least \"fraction\" data availability for windows of length \"windows\".\n",
    "\n",
    "    Args:\n",
    "        data_annual (xr.DataArray): Boolean mask in an annual mean resolution. i.e. Produced by annual_mask()\n",
    "        windows (list, optional): Window lengths to test.\n",
    "        fraction (float, optional): Fraction of data availability needed for a window to be considered available.\n",
    "        fillvalue (int, optional): Real values to fill when a startdate is not detected. Defaults to 2100.\n",
    "\n",
    "    Returns:\n",
    "        startyear: xarray DataArray with the start year for each region.\n",
    "    \"\"\"\n",
    "\n",
    "    # Center = False labels at the end of the window when I want the start. i.e. 1920 means the 1911-1920 mean\n",
    "    # True if year represents the beginning of a window with coverage >= fraction.\n",
    "    cumulative_avail_mask = mask_annual\n",
    "    for _length in windows:\n",
    "        _avail_mask = (mask_annual.rolling(\n",
    "                dim={\"year\": _length},\n",
    "                center=False,\n",
    "            ).sum() >= _length * fraction\n",
    "        ).shift(year=1 - _length, fill_value=True) # Shift so labelled by start and fill nans when incomplete\n",
    "        cumulative_avail_mask = cumulative_avail_mask & _avail_mask\n",
    "\n",
    "    startyear = mask_annual[\"year\"].where(cumulative_avail_mask).min(dim=\"year\")\n",
    "    startyear = startyear.where(cumulative_avail_mask.any(dim=\"year\"), fillvalue) # Fill nans if no available gaps\n",
    "\n",
    "    return startyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358317b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multidim_groupby_map(\n",
    "    data,\n",
    "    groupby_dims,\n",
    "    ffunc,\n",
    "    **ffunc_kwargs,\n",
    "):\n",
    "    '''\n",
    "    Hilarious recursive solution for the xarray groupby multiple dimensions problem. \n",
    "    xarray groupby objects cannot be grouped again, but you can map a function that does group them again.\n",
    "    The base case is that we are grouping by a single dimension, which xarray can handle.\n",
    "    Otherwise we groupby a new dimension and call our function on the remaining dimensions.\n",
    "    \n",
    "    Pass data as an xarray.DataArray, groupby_dims as a list, ffunc as the final function to apply,\n",
    "    and ffunc_kwargs as arguments for ffunc.\n",
    "    '''\n",
    "    if len(groupby_dims)==1:\n",
    "        return data.groupby(groupby_dims[0]).map(ffunc,**ffunc_kwargs) # using groupby_dims.pop() instead of groupby_dims[0] didn't work for some reason\n",
    "    return data.groupby(groupby_dims.pop()).map(multidim_groupby_map,groupby_dims=groupby_dims,ffunc=ffunc,**ffunc_kwargs)\n",
    "\n",
    "\n",
    "def annual_average_from_seasonal_averages(\n",
    "    data: xr.DataArray,\n",
    "):\n",
    "    \"\"\"Produce annual averages that weight seasons equally even if individual months are missing. \n",
    "\n",
    "    Args:\n",
    "        data (xr.DataArray): Data with a time dimension that can be grouped using\n",
    "        time.year and time.season.\n",
    "\n",
    "    Returns:\n",
    "        annual_avg (xr.DataArray): Averaged data\n",
    "    \"\"\"\n",
    "    \n",
    "    annual_avg = multidim_groupby_map(\n",
    "        data,\n",
    "        groupby_dims=[\"time.year\", \"time.season\"],\n",
    "        ffunc=xr.DataArray.mean,\n",
    "        skipna=True,\n",
    "        dim=[\"time\"],\n",
    "    ).mean(dim=\"season\")\n",
    "    \n",
    "    return annual_avg\n",
    "\n",
    "\n",
    "def reindex_time_by_startyear(\n",
    "    data_ann_avg: xr.DataArray,\n",
    "    startyears: xr.DataArray,\n",
    "    stack_vars: list = None,\n",
    "    spatial_str: str = \"z\"\n",
    "):\n",
    "    \"\"\"Reindex the temporal dimension so records begin according to a supplied array of start years.\n",
    "\n",
    "    Args:\n",
    "        data_ann_avg (xr.DataArray): Annually averaged data with a \"year\" time dimension.\n",
    "        startyears (xr.DataArray): Array of start years for the spatial dimensions of the data.\n",
    "        stack_vars (list, optional): If the spatial dimensions are more than 1, pass them here.. Defaults to None.\n",
    "        spatial_str (str, optional): Variable to assigned stacked spatial fields. Defaults to \"z\".\n",
    "\n",
    "    Returns:\n",
    "        xr.DataArray: Appropriately reindexed data with new time dimension \"recordlength\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # This doesn't work yet but it should eventually.\n",
    "    if stack_vars is not None:\n",
    "        data_stacked = data_ann_avg.stack({spatial_str: stack_vars})\n",
    "        startyears_stacked = startyears.stack({spatial_str: stack_vars})\n",
    "    else:\n",
    "        data_stacked = data_ann_avg\n",
    "        startyears_stacked = startyears\n",
    "\n",
    "    combino_list = []\n",
    "    for _spatial_startyear in startyears_stacked:\n",
    "        time_subset = data_stacked.sel(\n",
    "            {spatial_str: _spatial_startyear[spatial_str],\n",
    "             \"year\": slice(_spatial_startyear, None),\n",
    "             },\n",
    "        )\n",
    "\n",
    "        durations = np.arange(1, time_subset.year.shape[0] + 1)\n",
    "        \n",
    "        time_subset = time_subset.rename({\"year\": \"recordlength\"}).assign_coords(recordlength=durations)\n",
    "        combino_list.append(time_subset)\n",
    "\n",
    "    tseries_indexed_by_duration = xr.combine_nested(\n",
    "        combino_list,\n",
    "        concat_dim=[spatial_str],\n",
    "    )\n",
    "    if stack_vars is not None:\n",
    "        # Need to apply the multi-index again for some reason to be able to unstack.\n",
    "        tseries_indexed_by_duration = tseries_indexed_by_duration.set_index({spatial_str: stack_vars}).unstack(\"z\")\n",
    "    \n",
    "    return tseries_indexed_by_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ba238",
   "metadata": {},
   "source": [
    "## Compute internally consistent start dates for each data product.\n",
    "\n",
    "Compute the startdate for each ensemble member and take the latest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c26f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gistemp_tas_var = 'tas'\n",
    "hadcrut5_tas_var = 'tas'\n",
    "dcent_unfilled_tas_var = \"temperature\"\n",
    "best_tas_var = \"temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c06e5",
   "metadata": {},
   "source": [
    "#### GISTEMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b38f8",
   "metadata": {},
   "source": [
    "It is weird the GISTEMP has availability in Antarctica and confidence in it...but actually it agrees pretty well with HadCRUT5.\n",
    "\n",
    "E. Antarctica: 1960 (1957)  \n",
    "W. Antarctica: 1984 (never)  \n",
    "Arctic Ocean: 1931 (1933)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4bb43a",
   "metadata": {},
   "source": [
    "95% availability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9017b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "gistemp_startyear_list = []\n",
    "gistemp_availability_list = []\n",
    "for i, _file in enumerate(gistemp_5x5_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _gistemp_ds = xr.open_dataset(_file)[gistemp_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _gistemp_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    gistemp_startyear_list.append(_realization_startyears)\n",
    "    gistemp_availability_list.append(_availability_mask)\n",
    "    # break\n",
    "\n",
    "del _gistemp_ds\n",
    "gistemp_startyears = xr.concat(gistemp_startyear_list, dim=\"realization\")\n",
    "gistemp_availability = xr.concat(gistemp_availability_list, dim=\"realization\")\n",
    "gistemp_startyear_mid = gistemp_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "gistemp_startyear_final = xr.where(\n",
    "    gistemp_startyear_mid > earliest_startyear,\n",
    "    gistemp_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "gistemp_startyear_final = gistemp_startyear_final.where(gistemp_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del gistemp_startyear_mid, gistemp_startyear_list, gistemp_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb21cea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "gistemp_reindexed_list = []\n",
    "for i, _file in enumerate(gistemp_5x5_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _gistemp_ds = xr.open_dataset(_file)[gistemp_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = gistemp_availability.sel(realization=_gistemp_ds.realization)\n",
    "    \n",
    "    _gistemp_ann_avg = annual_average_from_seasonal_averages(_gistemp_ds).where(_mask)\n",
    "\n",
    "    _gistemp_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_gistemp_ann_avg,\n",
    "        startyears=gistemp_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    gistemp_reindexed_list.append(_gistemp_reindex)\n",
    "    # if i == 2: break\n",
    "gistemp_reindexed = xr.concat(gistemp_reindexed_list, dim=\"realization\")\n",
    "# del _gistemp_ds, gistemp_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e199ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gistemp_reindexed.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.95/ensembleChunks_0001_0200.reindexed.IPCCRegions.190001-202012.nc\")\n",
    "gistemp_availability.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.95/ensembleChunks_0001_0200.availability.IPCCRegions.190001-202012.nc\")\n",
    "gistemp_startyears.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.95/ensembleChunks_0001_0200.startyears.IPCCRegions.190001-202012.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efc81b",
   "metadata": {},
   "source": [
    "70% availability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424b30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "gistemp_startyear_list = []\n",
    "gistemp_availability_list = []\n",
    "for i, _file in enumerate(gistemp_5x5_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _gistemp_ds = xr.open_dataset(_file)[gistemp_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _gistemp_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    gistemp_startyear_list.append(_realization_startyears)\n",
    "    gistemp_availability_list.append(_availability_mask)\n",
    "    # break\n",
    "\n",
    "del _gistemp_ds\n",
    "gistemp_startyears = xr.concat(gistemp_startyear_list, dim=\"realization\")\n",
    "gistemp_availability = xr.concat(gistemp_availability_list, dim=\"realization\")\n",
    "gistemp_startyear_mid = gistemp_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "gistemp_startyear_final = xr.where(\n",
    "    gistemp_startyear_mid > earliest_startyear,\n",
    "    gistemp_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "gistemp_startyear_final = gistemp_startyear_final.where(gistemp_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del gistemp_startyear_mid, gistemp_startyear_list, gistemp_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f974811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "gistemp_reindexed_list = []\n",
    "for i, _file in enumerate(gistemp_5x5_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _gistemp_ds = xr.open_dataset(_file)[gistemp_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = gistemp_availability.sel(realization=_gistemp_ds.realization)\n",
    "    \n",
    "    _gistemp_ann_avg = annual_average_from_seasonal_averages(_gistemp_ds).where(_mask)\n",
    "\n",
    "    _gistemp_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_gistemp_ann_avg,\n",
    "        startyears=gistemp_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    gistemp_reindexed_list.append(_gistemp_reindex)\n",
    "    # if i == 2: break\n",
    "gistemp_reindexed = xr.concat(gistemp_reindexed_list, dim=\"realization\")\n",
    "# del _gistemp_ds, gistemp_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6505161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gistemp_reindexed.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.70/ensembleChunks_0001_0200.reindexed.IPCCRegions.190001-202012.nc\")\n",
    "gistemp_availability.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.70/ensembleChunks_0001_0200.availability.IPCCRegions.190001-202012.nc\")\n",
    "gistemp_startyears.to_netcdf(f\"{obslens_tseries_dir}/GISTEMP_5x5/20240820/xagg_correctedtime/threshold_0.70/ensembleChunks_0001_0200.startyears.IPCCRegions.190001-202012.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b3ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gistemp_reindexed, gistemp_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d4a8c",
   "metadata": {},
   "source": [
    "#### HadCRUT5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a6a83",
   "metadata": {},
   "source": [
    "95% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "hadcrut5_startyear_list = []\n",
    "hadcrut5_availability_list = []\n",
    "for i, _file in enumerate(hadcrut5_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _hadcrut5_ds = xr.open_dataset(_file)[hadcrut5_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _hadcrut5_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    hadcrut5_startyear_list.append(_realization_startyears)\n",
    "    hadcrut5_availability_list.append(_availability_mask)\n",
    "\n",
    "del _hadcrut5_ds\n",
    "hadcrut5_startyears = xr.concat(hadcrut5_startyear_list, dim=\"realization\")\n",
    "hadcrut5_availability = xr.concat(hadcrut5_availability_list, dim=\"realization\")\n",
    "hadcrut5_startyear_mid = hadcrut5_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "hadcrut5_startyear_final = xr.where(\n",
    "    hadcrut5_startyear_mid > earliest_startyear,\n",
    "    hadcrut5_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "hadcrut5_startyear_final = hadcrut5_startyear_final.where(hadcrut5_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del hadcrut5_startyear_mid, hadcrut5_startyear_list, hadcrut5_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f880c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "hadcrut5_reindexed_list = []\n",
    "for i, _file in enumerate(hadcrut5_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _hadcrut5_ds = xr.open_dataset(_file)[hadcrut5_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = hadcrut5_availability.sel(realization=_hadcrut5_ds.realization)\n",
    "    \n",
    "    _hadcrut5_ann_avg = annual_average_from_seasonal_averages(_hadcrut5_ds).where(_mask)\n",
    "\n",
    "    _hadcrut5_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_hadcrut5_ann_avg,\n",
    "        startyears=hadcrut5_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    hadcrut5_reindexed_list.append(_hadcrut5_reindex)\n",
    "    # if i == 2: break\n",
    "hadcrut5_reindexed = xr.concat(hadcrut5_reindexed_list, dim=\"realization\")\n",
    "hadcrut5_reindexed = hadcrut5_reindexed.sortby(\"realization\")\n",
    "\n",
    "del _hadcrut5_ds, hadcrut5_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "964e1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "hadcrut5_reindexed.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.95/HadCRUT.5.0.2.0.001_200.reindexed.IPCCRegions.190001-202412.nc\")\n",
    "hadcrut5_availability.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.95/HadCRUT.5.0.2.0.001_0200.availability.IPCCRegions.190001-202412.nc\")\n",
    "hadcrut5_startyears.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.95/HadCRUT.5.0.2.0.001_0200.startyears.IPCCRegions.190001-202412.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79b254",
   "metadata": {},
   "source": [
    "70% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77137ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "hadcrut5_startyear_list = []\n",
    "hadcrut5_availability_list = []\n",
    "for i, _file in enumerate(hadcrut5_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _hadcrut5_ds = xr.open_dataset(_file)[hadcrut5_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _hadcrut5_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    hadcrut5_startyear_list.append(_realization_startyears)\n",
    "    hadcrut5_availability_list.append(_availability_mask)\n",
    "\n",
    "del _hadcrut5_ds\n",
    "hadcrut5_startyears = xr.concat(hadcrut5_startyear_list, dim=\"realization\")\n",
    "hadcrut5_availability = xr.concat(hadcrut5_availability_list, dim=\"realization\")\n",
    "hadcrut5_startyear_mid = hadcrut5_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "hadcrut5_startyear_final = xr.where(\n",
    "    hadcrut5_startyear_mid > earliest_startyear,\n",
    "    hadcrut5_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "hadcrut5_startyear_final = hadcrut5_startyear_final.where(hadcrut5_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del hadcrut5_startyear_mid, hadcrut5_startyear_list, hadcrut5_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "069b6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "hadcrut5_reindexed_list = []\n",
    "for i, _file in enumerate(hadcrut5_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _hadcrut5_ds = xr.open_dataset(_file)[hadcrut5_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = hadcrut5_availability.sel(realization=_hadcrut5_ds.realization)\n",
    "    \n",
    "    _hadcrut5_ann_avg = annual_average_from_seasonal_averages(_hadcrut5_ds).where(_mask)\n",
    "\n",
    "    _hadcrut5_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_hadcrut5_ann_avg,\n",
    "        startyears=hadcrut5_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    hadcrut5_reindexed_list.append(_hadcrut5_reindex)\n",
    "    # if i == 2: break\n",
    "hadcrut5_reindexed = xr.concat(hadcrut5_reindexed_list, dim=\"realization\")\n",
    "hadcrut5_reindexed = hadcrut5_reindexed.sortby(\"realization\")\n",
    "\n",
    "del _hadcrut5_ds, hadcrut5_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6e85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "hadcrut5_reindexed.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.70/HadCRUT.5.0.2.0.001_200.reindexed.IPCCRegions.190001-202412.nc\")\n",
    "hadcrut5_availability.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.70/HadCRUT.5.0.2.0.001_0200.availability.IPCCRegions.190001-202412.nc\")\n",
    "hadcrut5_startyears.to_netcdf(f\"{obslens_tseries_dir}/HadCRUT5/20240820/xagg/threshold_0.70/HadCRUT.5.0.2.0.001_0200.startyears.IPCCRegions.190001-202412.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa471ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hadcrut5_reindexed, hadcrut5_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c7010",
   "metadata": {},
   "source": [
    "#### BEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5df1c",
   "metadata": {},
   "source": [
    "95% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3a4e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "best_startyear_list = []\n",
    "best_availability_list = []\n",
    "for i, _file in enumerate(best_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _best_ds = xr.open_dataset(_file)[best_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _best_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    best_startyear_list.append(_realization_startyears)\n",
    "    best_availability_list.append(_availability_mask)\n",
    "\n",
    "del _best_ds\n",
    "best_startyears = xr.concat(best_startyear_list, dim=\"realization\")\n",
    "best_availability = xr.concat(best_availability_list, dim=\"realization\")\n",
    "best_startyear_mid = best_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "best_startyear_final = xr.where(\n",
    "    best_startyear_mid > earliest_startyear,\n",
    "    best_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "best_startyear_final = best_startyear_final.where(best_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del best_startyear_mid, best_startyear_list, best_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f3b6863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "best_reindexed_list = []\n",
    "for i, _file in enumerate(best_95_files):\n",
    "    print(i, end=\" \")\n",
    "    _best_ds = xr.open_dataset(_file)[best_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = best_availability.sel(realization=i+1)\n",
    "    \n",
    "    _best_ann_avg = annual_average_from_seasonal_averages(_best_ds).where(_mask)\n",
    "\n",
    "    _best_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_best_ann_avg,\n",
    "        startyears=best_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    best_reindexed_list.append(_best_reindex)\n",
    "    # if i == 2: break\n",
    "best_reindexed = xr.concat(best_reindexed_list, dim=\"realization\")\n",
    "best_reindexed = best_reindexed.sortby(\"realization\")\n",
    "\n",
    "del _best_ds, best_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03fe0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "best_reindexed.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.95/Land_and_Ocean_LatLong1.reindexed.IPCCRegions.190001-202012.nc\")\n",
    "best_availability.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.95/Land_and_Ocean_LatLong1.availability.IPCCRegions.190001-202012.nc\")\n",
    "best_startyears.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.95/Land_and_Ocean_LatLong1.startyears.IPCCRegions.190001-202012.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dbe7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_reindexed, best_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2bddf",
   "metadata": {},
   "source": [
    "70% threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f3fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "earliest_startyear = 1900\n",
    "fillvalue = 2100\n",
    "best_startyear_list = []\n",
    "best_availability_list = []\n",
    "for i, _file in enumerate(best_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _best_ds = xr.open_dataset(_file)[best_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    \n",
    "    # Create mask of available by Nathan's GISTEMP standard but 4 seasons.\n",
    "    # Require 4 seasons because trends may be influenced by missing seasons.\n",
    "    _availability_mask = _best_ds.groupby(\"time.year\").map(annual_data, season_threshold=4)\n",
    "    _realization_startyears = startyear_running_availability(\n",
    "        _availability_mask,\n",
    "        fillvalue=fillvalue, # Mask nans into reals so that the quantile operation works later.\n",
    "    )\n",
    "\n",
    "    best_startyear_list.append(_realization_startyears)\n",
    "    best_availability_list.append(_availability_mask)\n",
    "\n",
    "del _best_ds\n",
    "best_startyears = xr.concat(best_startyear_list, dim=\"realization\")\n",
    "best_availability = xr.concat(best_availability_list, dim=\"realization\")\n",
    "best_startyear_mid = best_startyears.quantile(0.75, dim=\"realization\")\n",
    "# Set values less than 1900 to 1900.\n",
    "best_startyear_final = xr.where(\n",
    "    best_startyear_mid > earliest_startyear,\n",
    "    best_startyear_mid, \n",
    "    earliest_startyear,\n",
    ")\n",
    "best_startyear_final = best_startyear_final.where(best_startyear_final != fillvalue) # Revert masking to a nan\n",
    "del best_startyear_mid, best_startyear_list, best_availability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8d2a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    }
   ],
   "source": [
    "# Now iterate over the files and re-index them!\n",
    "\n",
    "best_reindexed_list = []\n",
    "for i, _file in enumerate(best_70_files):\n",
    "    print(i, end=\" \")\n",
    "    _best_ds = xr.open_dataset(_file)[best_tas_var].sel(time=slice(None,\"2020\"))\n",
    "    _mask = best_availability.sel(realization=i+1)\n",
    "    \n",
    "    _best_ann_avg = annual_average_from_seasonal_averages(_best_ds).where(_mask)\n",
    "\n",
    "    _best_reindex = reindex_time_by_startyear(\n",
    "        data_ann_avg=_best_ann_avg,\n",
    "        startyears=best_startyear_final,\n",
    "        spatial_str=\"RegionIndex\",\n",
    "    )\n",
    "    best_reindexed_list.append(_best_reindex)\n",
    "    # if i == 2: break\n",
    "best_reindexed = xr.concat(best_reindexed_list, dim=\"realization\")\n",
    "best_reindexed = best_reindexed.sortby(\"realization\")\n",
    "\n",
    "del _best_ds, best_reindexed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4918b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "best_reindexed.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.70/Land_and_Ocean_LatLong1.reindexed.IPCCRegions.190001-202012.nc\")\n",
    "best_availability.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.70/Land_and_Ocean_LatLong1.availability.IPCCRegions.190001-202012.nc\")\n",
    "best_startyears.to_netcdf(f\"{obslens_tseries_dir}/BEST/20250320/xagg/threshold_0.70/Land_and_Ocean_LatLong1.startyears.IPCCRegions.190001-202012.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f17d1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "del best_reindexed, best_availability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_xagg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
