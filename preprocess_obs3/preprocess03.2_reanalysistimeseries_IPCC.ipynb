{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5702ab-4316-47a2-af40-56d7ce8ccb57",
   "metadata": {},
   "source": [
    "# Process gridded observation data into timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467a1d3-5c6e-4ba9-83a1-91cbaa34bd84",
   "metadata": {},
   "source": [
    "## 2025/03/23\n",
    "\n",
    "Include reanalysis in preprocessing for comparison with other data products.\n",
    "\n",
    "The criterion for considering regions unobserved (>10% missing data) is reasonable, but the impact of this threshold on the results should be discussed.\n",
    "\n",
    "The data availability threshold influences our results by determining the “start year” in which observations are considered complete running into the future. This influences both the trend at any given year (since it may start earlier or later with a different availability threshold) and the envelope of internal variability (since a longer and earlier beginning trend has less internal variability). The estimate the impact of our threshold on the results, we have recalculated the start date with more (5%) and less (30%) stringent thresholds. The change in record start years is now included as a supplementary figure (Figure S??). Overall, we see that the influence of the availability threshold on the start year is small (<X years) in most regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18476b97-1df5-45f3-a446-f25bcbe6a735",
   "metadata": {},
   "source": [
    "__1. Process the gridded temperature data into timeseries for each observational product.__\n",
    "\n",
    "Output is a dataArray for each model with dimensions of time and IPCC region containing a time series of the TAS variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ff2a2-aa9a-4f90-927d-3d5773e96f1d",
   "metadata": {},
   "source": [
    "Use this tool:  \n",
    "\n",
    "https://github.com/IPCC-WG1/Atlas/blob/main/notebooks/reference-regions_Python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e0e42-e328-46dd-884a-4259b363feda",
   "metadata": {},
   "source": [
    "For now, I will create my code for the CESM1 and MPI models so that it can be generalized easily. I can pull some code from my climatetrend_uncertainty repository (climatetrend_uncertainty/initial_code/PIC_timeseries_preproc.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede891f-af88-4e6d-90de-32be78682d2b",
   "metadata": {},
   "source": [
    "## Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b60071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import xagg as xa\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "import subprocess\n",
    "\n",
    "regionmask.__version__\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dde00",
   "metadata": {},
   "source": [
    "__From Adam Phillips via Nathan Lenssen:__  \n",
    "\n",
    "Hi Nathan,  \n",
    "Yes. A few months ago we started copying some of observational + reanalysis data over to /glade/campaign/cgd/cas/observations/.   \n",
    "You can find monthly ERA5 t2m data here:  \n",
    "/glade/campaign/cgd/cas/observations/ERA5/mon/t2m/era5.t2m.194001-202412.nc (at ~1/4 degree resolution)\n",
    "and I just copied over what MERRA2 data we have to here:  \n",
    "/glade/campaign/cgd/cas/observations/MERRA2/mon/T2M_MERRA2_asm_mon_198001_202012.nc (at 1/2 degree resolution)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac026e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_datapath = \"/glade/campaign/cgd/cas/observations/ERA5/mon/t2m/era5.t2m.194001-202412.nc\"\n",
    "merra2_datapath = \"/glade/campaign/cgd/cas/observations/MERRA2/mon/T2M_MERRA2_asm_mon_198001_202012.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50005e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_tas_var = 't2m'\n",
    "merra2_tas_var = 'T2M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92608d6-3949-45ee-89fd-19d6e76e05ca",
   "metadata": {},
   "source": [
    "### Load and process timeseries according to IPCC Region designations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a26d54",
   "metadata": {},
   "source": [
    "Mask data based on availability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c542cba-5b9a-4dd6-bfac-3125cd91a746",
   "metadata": {},
   "source": [
    "### 2. Do masking for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715917fd-71c2-414d-ab05-82b965bf8003",
   "metadata": {},
   "source": [
    "Variable is \"tempAnom\". \"record\" coordinate will allow for easier concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65508295-9416-4b0a-8e66-9856954f215b",
   "metadata": {},
   "source": [
    "### Loop over observation files and compute the regional means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38a2000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ipccregion_timeseries_xagg(\n",
    "    ds_filepath:str,\n",
    "    ds_var:str,\n",
    "    model_str:str,\n",
    "    cesm=False,\n",
    "    read_wm=True,\n",
    "    write_wm=True,\n",
    "    new_times=None,\n",
    "    ufunc=None,\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Compute timeseries for all IPCC AR6 regions when given a simple model output file.\n",
    "    Now using xagg to appropriately weight gridcells that fall partly within a region!\n",
    "    '''\n",
    "    # Load data\n",
    "    ds = xr.open_dataset(ds_filepath)\n",
    "    \n",
    "    if ufunc is not None:\n",
    "        print(ufunc)\n",
    "        ds = ufunc(ds)\n",
    "    \n",
    "    try:\n",
    "        ds = ds.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Correct time if CESM\n",
    "    if cesm:\n",
    "        ds  = fix_cesm_time(ds)\n",
    "    \n",
    "    if new_times is not None:\n",
    "        ds[\"time\"] = new_times\n",
    "\n",
    "    da = ds[ds_var]\n",
    "\n",
    "    xagg_dir = \"/glade/u/home/jonahshaw/w/trend_uncertainty/nathan/xagg_resources\"\n",
    "    xa.set_options(rgrd_alg='bilinear',nan_to_zero_regridding=False)\n",
    "\n",
    "    if (read_wm and os.path.exists(os.path.join(xagg_dir, f'wm_{model_str}'))):\n",
    "        # Load weightmap\n",
    "        weightmap = xa.read_wm(os.path.join(xagg_dir, f'wm_{model_str}'))\n",
    "    else:\n",
    "        # Load IPCC region shp file:\n",
    "        ipcc_wgi_regions_shp = \"IPCC-WGI-reference-regions-v4.shp\"\n",
    "        gdf = gpd.read_file(os.path.join(xagg_dir, ipcc_wgi_regions_shp))\n",
    "                \n",
    "        # Compute weights for entire grid. Assuming lat, lon, time dimension on input\n",
    "        area_weights = np.cos(np.deg2rad(da.lat)).broadcast_like(da.isel(time=0).squeeze())\n",
    "        \n",
    "        weightmap = xa.pixel_overlaps(da, gdf, weights=area_weights)\n",
    "        # Save the weightmap for later:\n",
    "        if write_wm:\n",
    "            weightmap.to_file(os.path.join(xagg_dir, f'wm_{model_str}'))\n",
    "\n",
    "    # Aggregate\n",
    "    with xa.set_options(silent=True):\n",
    "        aggregated = xa.aggregate(da, weightmap)\n",
    "    # aggregated = xa.aggregate(da, weightmap)\n",
    "    \n",
    "    # Convert to an xarray dataset\n",
    "    aggregated_ds = aggregated.to_dataset()\n",
    "    # Change xarray formatting to match previous file organization.\n",
    "    aggregated_ds = aggregated_ds.set_coords((\"Continent\", \"Type\", \"Name\", \"Acronym\")).rename({\"poly_idx\": \"RegionIndex\", \"Name\": \"RegionName\", \"Acronym\": \"RegionAbbrev\"})\n",
    "        \n",
    "    return aggregated_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "315a888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wrapper(\n",
    "    ds_filepath:str,\n",
    "    save_filepath:str,\n",
    "    ds_var:str,\n",
    "    model_str:str,\n",
    "    ufunc=None,\n",
    "    new_times=None,\n",
    "):\n",
    "    aggregated_ds = create_ipccregion_timeseries_xagg(\n",
    "        ds_filepath=ds_filepath,\n",
    "        ds_var=ds_var,\n",
    "        model_str=model_str,\n",
    "        new_times=new_times,\n",
    "        ufunc=ufunc,\n",
    "    )\n",
    "\n",
    "    aggregated_ds.to_netcdf(path=save_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_valid_time_to_time(ds: xr.Dataset) -> xr.Dataset:\n",
    "#     \"\"\"\n",
    "#     Rename the 'valid_time' coordinate to 'time' in the input xarray Dataset.\n",
    "#     \"\"\"\n",
    "#     return ds.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "# lambda x: x.rename({\"valid_time\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "427058fd-59d9-47c1-a796-6352baa885f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/glade/u/home/jonahshaw/w/trend_uncertainty/nathan/OBS_LENS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499d628",
   "metadata": {},
   "source": [
    "### ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d4673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_subdir = 'ERA5/20250323/xagg/'\n",
    "\n",
    "if not os.path.exists(os.path.join(save_dir,model_subdir)):\n",
    "    os.makedirs(os.path.join(save_dir,model_subdir))\n",
    "    \n",
    "_ds_var = era5_tas_var\n",
    "_ds_filepath = era5_datapath\n",
    "\n",
    "filename = _ds_filepath.split('/')[-1]\n",
    "_outfilepath = '%s/%s/%s' % (save_dir,model_subdir,filename)\n",
    "\n",
    "tasks = []\n",
    "\n",
    "if os.path.exists(_outfilepath):\n",
    "    print('Skipping %s' % _outfilepath)\n",
    "\n",
    "else:\n",
    "    tasks.append(dask.delayed(aggregate_wrapper)(\n",
    "        ds_filepath=_ds_filepath,\n",
    "        save_filepath=_outfilepath,\n",
    "        ds_var=_ds_var,\n",
    "        model_str=\"ERA5\",\n",
    "        ufunc=lambda x: x.rename({\"valid_time\": \"time\"}),\n",
    "        new_times=None,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a66730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jonahshaw/conda-envs/py_xagg/lib/python3.12/site-packages/dask_jobqueue/pbs.py:82: FutureWarning: project has been renamed to account as this kwarg was used wit -A option. You are still using it (please also check config files). If you did not set account yet, project will be respected for now, but it will be removed in a future release. If you already set account, project is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/glade/work/jonahshaw/conda-envs/py_xagg/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39611 instead\n",
      "  warnings.warn(\n",
      "/glade/work/jonahshaw/conda-envs/py_xagg/lib/python3.12/site-packages/dask_jobqueue/pbs.py:82: FutureWarning: project has been renamed to account as this kwarg was used wit -A option. You are still using it (please also check config files). If you did not set account yet, project will be respected for now, but it will be removed in a future release. If you already set account, project is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Launch a Dask cluster using PBSCluster\n",
    "try:\n",
    "    cluster = PBSCluster(cores    = 1,\n",
    "                        memory   = '32GB',\n",
    "                        queue    = 'casper',\n",
    "                        walltime = '00:15:00',\n",
    "                        project  = 'UCUC0007',\n",
    "                        )\n",
    "    cluster.scale(jobs=1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    dask.compute(*tasks)\n",
    "\n",
    "    client.shutdown()\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c7dca",
   "metadata": {},
   "source": [
    "### MERRA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f16592ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_subdir = 'MERRA2/20250323/xagg/'\n",
    "\n",
    "if not os.path.exists(os.path.join(save_dir,model_subdir)):\n",
    "    os.makedirs(os.path.join(save_dir,model_subdir))\n",
    "    \n",
    "_ds_var = merra2_tas_var\n",
    "_ds_filepath = merra2_datapath\n",
    "\n",
    "filename = _ds_filepath.split('/')[-1]\n",
    "_outfilepath = '%s/%s/%s' % (save_dir,model_subdir,filename)\n",
    "\n",
    "tasks = []\n",
    "\n",
    "if os.path.exists(_outfilepath):\n",
    "    print('Skipping %s' % _outfilepath)\n",
    "\n",
    "else:\n",
    "    tasks.append(dask.delayed(aggregate_wrapper)(\n",
    "        ds_filepath=_ds_filepath,\n",
    "        save_filepath=_outfilepath,\n",
    "        ds_var=_ds_var,\n",
    "        model_str=\"MERRA2\",\n",
    "        ufunc=None,\n",
    "        new_times=None,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jonahshaw/conda-envs/py_xagg/lib/python3.12/site-packages/dask_jobqueue/pbs.py:82: FutureWarning: project has been renamed to account as this kwarg was used wit -A option. You are still using it (please also check config files). If you did not set account yet, project will be respected for now, but it will be removed in a future release. If you already set account, project is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/glade/work/jonahshaw/conda-envs/py_xagg/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46419 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Launch a Dask cluster using PBSCluster\n",
    "cluster = PBSCluster(cores    = 1,\n",
    "                    memory   = '32GB',\n",
    "                    queue    = 'casper',\n",
    "                    walltime = '00:15:00',\n",
    "                    project  = 'UCUC0007',\n",
    "                    )\n",
    "cluster.scale(jobs=1)\n",
    "client = Client(cluster)\n",
    "\n",
    "dask.compute(*tasks)\n",
    "\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3eb21d",
   "metadata": {},
   "source": [
    "Interpolate to 5x5 degree resolution for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b3b94",
   "metadata": {},
   "source": [
    "Clean-up dask workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2afd06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f405ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/\"\n",
    "daskworker_list = glob.glob(f\"{working_dir}/dask-worker.????????\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1896f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169091\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169091\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169087\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169087\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169103\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169103\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169094\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169094\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169097\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169097\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169097\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169097\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169094\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169094\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169087\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169087\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169101\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.e4169101\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169103\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169103\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169091\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169091\n",
      "/glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169101\n",
      "Removed: /glade/u/home/jonahshaw/Scripts/git_repos/internalvar-vs-obsunc/preprocess_obs3/dask-worker.o4169101\n"
     ]
    }
   ],
   "source": [
    "for file_path in daskworker_list:\n",
    "    print(file_path)\n",
    "    try:\n",
    "        subprocess.run(['rm', '-f', file_path], check=True)\n",
    "        print(f\"Removed: {file_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error removing {file_path}: {e}\")\n",
    "    # break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b8825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_xagg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
